<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- AWS S3 Connector Configuration for Hadoop 3.3.6 -->
    
    <!-- S3 Endpoint Configuration -->
    <property>
        <name>fs.s3a.endpoint</name>
        <value>s3.amazonaws.com</value>
        <description>AWS S3 endpoint to connect to. Default is s3.amazonaws.com</description>
    </property>
    
    <!-- Authentication Configuration -->
    <property>
        <name>fs.s3a.access.key</name>
        <value>YOUR_ACCESS_KEY</value>
        <description>AWS access key ID. Omit for IAM role-based or provider-based authentication.</description>
    </property>
    
    <property>
        <name>fs.s3a.secret.key</name>
        <value>YOUR_SECRET_KEY</value>
        <description>AWS secret key. Omit for IAM role-based or provider-based authentication.</description>
    </property>
    
    <!-- AWS Region Configuration -->
    <property>
        <name>fs.s3a.region</name>
        <value>us-east-1</value>
        <description>AWS S3 region. This is the recommended way to configure the region.</description>
    </property>
    
    <!-- Connection Configuration -->
    <property>
        <name>fs.s3a.connection.maximum</name>
        <value>100</value>
        <description>Maximum number of simultaneous connections to S3.</description>
    </property>
    
    <property>
        <name>fs.s3a.connection.timeout</name>
        <value>200000</value>
        <description>Socket connection timeout in milliseconds.</description>
    </property>
    
    <!-- Performance Tuning -->
    <property>
        <name>fs.s3a.threads.max</name>
        <value>20</value>
        <description>Maximum number of threads for S3A transfer operations.</description>
    </property>
    
    <property>
        <name>fs.s3a.connection.establish.timeout</name>
        <value>5000</value>
        <description>Socket connection setup timeout in milliseconds.</description>
    </property>
    
    <property>
        <name>fs.s3a.attempts.maximum</name>
        <value>20</value>
        <description>Maximum number of retry attempts for S3 operations.</description>
    </property>
    
    <!-- Read/Write Performance -->
    <property>
        <name>fs.s3a.readahead.range</name>
        <value>1048576</value>
        <description>Bytes to read ahead during a seek operation. Default is 1MB.</description>
    </property>
    
    <property>
        <name>fs.s3a.multipart.size</name>
        <value>104857600</value>
        <description>Size of each multipart upload part. Default is 100MB.</description>
    </property>
    
    <property>
        <name>fs.s3a.multipart.threshold</name>
        <value>104857600</value>
        <description>Threshold before uploads use multipart upload. Default is 100MB.</description>
    </property>
    
    <!-- Fast Upload Configuration -->
    <property>
        <name>fs.s3a.fast.upload</name>
        <value>true</value>
        <description>Enable fast upload by using disk buffering.</description>
    </property>
    
    <property>
        <name>fs.s3a.fast.upload.buffer</name>
        <value>disk</value>
        <description>Buffer type to use for uploads: disk, array, or bytebuffer.</description>
    </property>
    
    <!-- Path Style Access (if needed) -->
    <!--
    <property>
        <name>fs.s3a.path.style.access</name>
        <value>false</value>
        <description>Enable path style access. Default is false (use virtual hosting).</description>
    </property>
    -->
    
    <!-- Server-Side Encryption (if needed) -->
    <!--
    <property>
        <name>fs.s3a.server-side-encryption-algorithm</name>
        <value>AES256</value>
        <description>Encryption algorithm. Options: AES256 or SSE-KMS.</description>
    </property>
    -->
    
    <!-- Committer Configuration for Spark/Hive -->
    <property>
        <name>fs.s3a.committer.name</name>
        <value>magic</value>
        <description>Committer to use: magic, directory, partitioned, or file.</description>
    </property>
    
    <!-- Retry Configuration -->
    <property>
        <name>fs.s3a.retry.limit</name>
        <value>7</value>
        <description>Number of times to retry any throttled request.</description>
    </property>
    
    <property>
        <name>fs.s3a.retry.interval</name>
        <value>500ms</value>
        <description>Base sleep time for retries, increases exponentially.</description>
    </property>
    
    <!-- S3A Filesystem Implementation -->
    <property>
        <name>fs.s3a.impl</name>
        <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
        <description>The implementation class of the S3A Filesystem.</description>
    </property>
    
    <!-- AWS SDK Connection Settings -->
    <property>
        <name>fs.s3a.connection.ssl.enabled</name>
        <value>true</value>
        <description>Enables or disables SSL connections to S3.</description>
    </property>
    
    <!-- For Hive/Spark Integration -->
    <property>
        <name>fs.s3a.buffer.dir</name>
        <value>${hadoop.tmp.dir}/s3a</value>
        <description>Temporary directory for storing data being uploaded to S3.</description>
    </property>
    
    <!-- Input Strategy for Hive/Spark -->
    <property>
        <name>fs.s3a.experimental.input.fadvise</name>
        <value>sequential</value>
        <description>Policy for reading files: sequential, random, or normal.</description>
    </property>
</configuration>
